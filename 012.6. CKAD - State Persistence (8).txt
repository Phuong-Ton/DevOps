Module 8: State Persistence - 16 Lessons
8.1 Introduction to Docker Storage 00:54
8.2 Storage in Docker 12:32
8.3 Volume Driver Plugins in Docker 01:53
8.4 Volumes in Kubernetes 04:36

apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  container:
  - name: my-pod-container
    image: alpine
    command: ["/bin/sh","-c"]
	args: ["shuf -i 0-100 -n 1 >> /opt/number.out;"] 
	
	volumeMounts:
	- mountPath: /otp
	  name: "data-volume"
--------------------------------------------------------
  volumes:
  - name: "data-volume"
    hostPath: 
	  path: /data
	  type: Directory
-> save on node
--------------------------------------------------------
  volumes:
  - name: "data-volume"
    awsElasticBlockStore:
	  volumnID: <volume-id>
	  fsType: ext4
-> save on EBS AWS
---------------------------------------------------------

8.5 Persistent Volumes 03:07

a lot of users, pods -> config Pod -> difficult deploy in large enviroment
-> config every time for each pod
===> need to storage data centrally -> PV can help this problem
PV1
-----------------------
| PVC1   PVC2    PVC3 |
-----------------------
   ^      ^      ^
   Node1  |      |
         Node2   |
		        Node3

apiVersion: v1
kind: PersistentVolume
metadata: my-pv-vol1
spec:
  accessModes:
    - ReadWriteOnce/ ReadOnlyMany/ ReadWriteMany
  capacity:
    storage: 1Gi
-------------------------------------------------------
  hostPath:
    path /tmp/data                                Node
-------------------------------------------------------
  awsElasticBlockStore:
    volumnID: <volume-id>
   fsType: ext4                                 EBS AWS
-------------------------------------------------------
8.6 Persistent Volume Claims 04:05
- make storage availalbe on the node
2 separate object in one namespace

Using labels an selector to bind PV and PVC > 1-1 relationship

apiVersion: v1
kind: PersistentVolumeClaim
metadata: 
  name: my-pvc-vol1
spec:
  accessModes: 
    - ReadWriteOnce
  resources:
    requests:
	  storage: 500Mi
	  
kubectl get pvc 
if no more pvc , kubernetes	will choose my-pv-vol1
status PENDING -> BOUND

kubectl delete pvc my-pvc-vol1

persistentVolumeClaimPolicy: Retain / Delete / Recycle


8.7 Using PVCs in Pods
Once you create a PVC use it in a POD definition file by specifying the PVC Claim name under persistentVolumeClaim section in the volumes section like this:

apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
    - name: myfrontend
      image: nginx
      volumeMounts:
      - mountPath: "/var/www/html"
        name: mypd
  volumes:
    - name: mypd
      persistentVolumeClaim:
        claimName: myclaim
The same is true for ReplicaSets or Deployments. Add this to the pod template section of a Deployment on ReplicaSet.
Reference URL: https://kubernetes.io/docs/concepts/storage/persistent-volumes/#claims-as-volumes
==============================================================================================================================
8.8 Practice Test - Kubernetes - CKAD - Persistent Volumes
8.9 Solution - Persistent Volumes and Persistent Volume Claims (optional) 18:11
You don't get what you wish for. You get what you work for.
01. The application stores logs at location /log/app.log. View the logs.
You can exec in to the container and open the file:
kubectl exec webapp -- cat /log/app.log

controlplane ~ ➜  kubectl exec webapp -- cat /log/app.log

[2024-09-20 18:57:47,165] WARNING in event-simulator: USER5 Failed to Login as the account is locked due to MANY FAILED ATTEMPTS.
[2024-09-20 18:57:47,165] WARNING in event-simulator: USER7 Order failed as the item is OUT OF STOCK.
[2024-09-20 18:57:47,165] INFO in event-simulator: USER4 logged out
[2024-09-20 18:57:48,165] INFO in event-simulator: USER3 is viewing page2
[2024-09-20 18:57:49,166] INFO in event-simulator: USER3 is viewing page3
[2024-09-20 18:57:50,167] INFO in event-simulator: USER1 is viewing page2

controlplane ~ ➜  alias k=kubectl

controlplane ~ ➜  k get pod
NAME     READY   STATUS    RESTARTS   AGE
webapp   1/1     Running   0          16m

controlplane ~ ➜  k describe pod webapp
Name:             webapp
Namespace:        default
Priority:         0
Service Account:  default
Node:             controlplane/192.43.164.9
Start Time:       Fri, 20 Sep 2024 18:39:41 +0000
Labels:           <none>
Annotations:      <none>
Status:           Running
IP:               10.244.0.4
IPs:
  IP:  10.244.0.4
Containers:
  event-simulator:
    Container ID:   containerd://af7afb140df20c61cc6e6f1035c73c38c55508265d72e1420d850e3ef22d3d98
    Image:          kodekloud/event-simulator
    Image ID:       docker.io/kodekloud/event-simulator@sha256:1e3e9c72136bbc76c96dd98f29c04f298c3ae241c7d44e2bf70bcc209b030bf9
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Fri, 20 Sep 2024 18:39:45 +0000
    Ready:          True
    Restart Count:  0
    Environment:
      LOG_HANDLERS:  file
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-4tl9h (ro)
Conditions:
  Type                        Status
  PodReadyToStartContainers   True 
  Initialized                 True 
  Ready                       True 
  ContainersReady             True 
  PodScheduled                True 
Volumes:
  kube-api-access-4tl9h:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  17m   default-scheduler  Successfully assigned default/webapp to controlplane
  Normal  Pulling    17m   kubelet            Pulling image "kodekloud/event-simulator"
  Normal  Pulled     17m   kubelet            Successfully pulled image "kodekloud/event-simulator" in 2.8s (2.8s including waiting). Image size: 28855042 bytes.
  Normal  Created    17m   kubelet            Created container event-simulator
  Normal  Started    17m   kubelet            Started container event-simulator
------------------------------------------------------------------------------------------------------
02. Configure a volume to store these logs at /var/log/webapp on the host.
Use the spec provided below.
Name: webapp

Image Name: kodekloud/event-simulator
Volume HostPath: /var/log/webapp
Volume Mount: /log

-->
Use the command kubectl get po webapp -o yaml > webapp.yaml and add the given properties under the spec.volumes and spec.containers.volumeMounts.
OR
Use the command kubectl run to create a new pod and use the flag --dry-run=client -o yaml to generate the manifest file.
In the manifest file add spec.volumes and spec.containers.volumeMounts property.

After that, run the following command to create a pod called webapp: -
kubectl replace -f webapp.yaml --force
kubectl replace -f: - It will remove the existing resource and will replace it with the new one from the given manifest file.

apiVersion: v1
kind: Pod
metadata:
  name: webapp
spec:
  containers:
  - name: event-simulator
    image: kodekloud/event-simulator
    env:
    - name: LOG_HANDLERS
      value: file
    volumeMounts:
    - mountPath: /log
      name: log-volume

  volumes:
  - name: log-volume
    hostPath:
      # directory location on host
      path: /var/log/webapp
      # this field is optional
      type: Directory

controlplane ~ ➜  diff bef_webapp.yaml aft_webapp.yaml 
23a24,25
>     - mountPath: /log
>       name: my-log-volume
44a47,50
>   - name: my-log-volume
>     hostPath:
>       path: /var/log/webapp
>      

controlplane ~ ✖ kubectl create -f aft_webapp.yaml 
pod/webapp created

controlplane ~ ➜  kubectl get pv
No resources found

controlplane ~ ➜  kubectl get pod
NAME     READY   STATUS    RESTARTS   AGE
webapp   1/1     Running   0          23s
	  
-------------------------------------------------------------------

03.Create a Persistent Volume with the given specification.

Volume Name: pv-log
Storage: 100Mi
Access Modes: ReadWriteMany
Host Path: /pv/log
Reclaim Policy: Retain



controlplane ~ ➜  k create -f pv_log.yaml 
persistentvolume/pv-log created

controlplane ~ ➜  cat pv_log.yaml 
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-log
spec:
  accessModes:
  - ReadWriteMany
  capacity: 
    storage: 100Mi
  hostPath:
    path: /pv/log
  persistentVolumeReclaimPolicy: Retain
  
  
  ---------------------------------------
04.Let us claim some of that storage for our application. Create a Persistent Volume Claim with the given specification.

Volume Name: claim-log-1
Storage Request: 50Mi
Access Modes: ReadWriteOnce

controlplane ~ ➜  cat pvc_log.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: claim-log-1
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 50Mi

controlplane ~ ➜  cat pv_log.yaml 
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-log
spec:
  accessModes:
  - ReadWriteMany
  capacity: 
    storage: 100Mi
  hostPath:
    path: /pv/log
  persistentVolumeReclaimPolicy: Retain
 
controlplane ~ ➜  k get pvc
NAME          STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
claim-log-1   Pending 

controlplane ~ ➜  k get pv
NAME     CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pv-log   100Mi      RWX            Retain           Available                          <unset>                          6m44s

----------------------------------------
05.Update the Access Mode on the claim to bind it to the PV.
Delete and recreate the claim-log-1.

Volume Name: claim-log-1
Storage Request: 50Mi
PVol: pv-log
Status: Bound
-->
controlplane ~ ➜  kubectl delete pvc claim-log-1 
persistentvolumeclaim "claim-log-1" deleted

controlplane ~ ➜  cp pvc.yaml aft_pvc.yaml

controlplane ~ ➜  vi aft_pvc.yaml 

controlplane ~ ➜  diff pvc.yaml aft_pvc.yaml 
7c7
<   - ReadWriteOnce
---
>   - ReadWriteMany

controlplane ~ ✖ kubectl create -f aft_pvc.yaml 
persistentvolumeclaim/claim-log-1 created

controlplane ~ ➜  kubectl get pv,pvc
NAME                      CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                 STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
persistentvolume/pv-log   100Mi      RWX            Retain           Bound    default/claim-log-1                  <unset>                          5m11s

NAME                                STATUS   VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
persistentvolumeclaim/claim-log-1   Bound    pv-log   100Mi      RWX                           <unset>                 23s


----------------------------------------------------------------
06.Update the webapp pod to use the persistent volume claim as its storage.
Replace hostPath configured earlier with the newly created PersistentVolumeClaim.

Name: webapp
Image Name: kodekloud/event-simulator
Volume: PersistentVolumeClaim=claim-log-1
Volume Mount: /log

  volumes:
    - name: mypd
      persistentVolumeClaim:
        claimName: myclaim

controlplane ~ ➜  kubectl delete pvc claim-log-1 
persistentvolumeclaim "claim-log-1" deleted

controlplane ~ ➜  cp pvc.yaml aft_pvc.yaml

controlplane ~ ➜  vi aft_pvc.yaml 

controlplane ~ ➜  diff pvc.yaml aft_pvc.yaml 
7c7
<   - ReadWriteOnce
---
>   - ReadWriteMany

controlplane ~ ✖ kubectl create -f aft_pvc.yaml 
persistentvolumeclaim/claim-log-1 created

controlplane ~ ➜  kubectl get pv,pvc
NAME                      CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                 STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
persistentvolume/pv-log   100Mi      RWX            Retain           Bound    default/claim-log-1                  <unset>                          5m11s

NAME                                STATUS   VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
persistentvolumeclaim/claim-log-1   Bound    pv-log   100Mi      RWX                           <unset>                 23s

------------------------------------------------------------
controlplane ~ ➜  kubectl delete pvc claim-log-1 
persistentvolumeclaim "claim-log-1" deleted
^C
controlplane ~ ✖ kubectl get pvc
NAME          STATUS        VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
claim-log-1   Terminating   pv-log   100Mi      RWX                           <unset>                 7m44s

controlplane ~ ➜  kubectl get pvc
NAME          STATUS        VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
claim-log-1   Terminating   pv-log   100Mi      RWX                           <unset>                 7m50s

controlplane ~ ➜  kubectl get pvc
NAME          STATUS        VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
claim-log-1   Terminating   pv-log   100Mi      RWX                           <unset>                 7m51s

controlplane ~ ➜  kubectl get pvc
NAME          STATUS        VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
claim-log-1   Terminating   pv-log   100Mi      RWX                           <unset>                 7m53s

controlplane ~ ➜  kubectl delete pod webapp 
pod "webapp" deleted

controlplane ~ ➜  ^C

controlplane ~ ✖ kubectl get pvc
No resources found in default namespace.

controlplane ~ ➜  kubectl get pod

controlplane ~ ➜  kubectl get pv
NAME     CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS     CLAIM                 STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pv-log   100Mi      RWX            Retain           Released   default/claim-log-1                  <unset>


8.10 Note on optional topics
We have covered the required topics for the exam for the Storage section. The remaining topics in this section are provided based on student demand and not part of the exam curriculum. If your focus is only to cover the topics for the exam, please proceed to the next section.

8.11 Storage Classes 03:59
8.12 Practice Test - Storage Class
controlplane ~ ➜  kubectl get sc
NAME                   PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
local-path (default)   rancher.io/local-path   Delete          WaitForFirstConsumer   false                  10m


controlplane ~ ➜  kubectl get sc
NAME                        PROVISIONER                     RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
local-path (default)        rancher.io/local-path           Delete          WaitForFirstConsumer   false                  11m
local-storage               kubernetes.io/no-provisioner    Delete          WaitForFirstConsumer   false                  12s
portworx-io-priority-high   kubernetes.io/portworx-volume   Delete          Immediate              false                  12s

controlplane ~ ➜  
Look for the storage class name that uses no-provisioner
The local-storage storage class makes use of the no-provisioner and currently does not support dynamic provisioning.
Refer to the tab above the terminal (called Local Storage) to read more about it.
-----------------------------------------------------
Let's fix that. Create a new PersistentVolumeClaim by the name of local-pvc that should bind to the volume local-pv.
Inspect the pv local-pv for the specs.

PVC: local-pvc
Correct Access Mode?
Correct StorageClass Used?
PVC requests volume size = 500Mi?
controlplane ~ ➜  kubectl describe pv local-pv 
Name:              local-pv
Labels:            <none>
Annotations:       <none>
Finalizers:        [kubernetes.io/pv-protection]
StorageClass:      local-storage
Status:            Available
Claim:             
Reclaim Policy:    Retain
Access Modes:      RWO
VolumeMode:        Filesystem
Capacity:          500Mi
Node Affinity:     
  Required Terms:  
    Term 0:        kubernetes.io/hostname in [controlplane]
Message:           
Source:
    Type:  LocalVolume (a persistent volume backed by local storage on a node)
    Path:  /opt/vol1
Events:    <none>

controlplane ~ ➜  vi pvc

controlplane ~ ➜  vi pvc.yaml 

controlplane ~ ➜  kubectl create -f pvc.yaml 
persistentvolumeclaim/local-pvc created

controlplane ~ ➜  vi pvc.yaml 

controlplane ~ ➜  kubectt get pod,pvc
-bash: kubectt: command not found

controlplane ~ ✖ kubectl get pod,pvc
NAME                              STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
persistentvolumeclaim/local-pvc   Pending                                      local-path     <unset>                 110s

controlplane ~ ➜  kubectl delete pvc local-pvc 
persistentvolumeclaim "local-pvc" deleted

controlplane ~ ➜  kubectl create -f pvc.yaml 
persistentvolumeclaim/local-pvc created

controlplane ~ ➜  cat pvc.yaml 
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: local-pvc
spec:
  accessModes:
  - ReadWriteOnce
  storageClassName: local-storage 
  resources:
    requests:
      storage: 500Mi

controlplane ~ ➜  kubectl get pvc
NAME        STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS    VOLUMEATTRIBUTESCLASS   AGE
local-pvc   Pending                                      local-storage   <unset>                 72s

Why is the PVC in a pending state despite making a valid request to claim the volume called local-pv?
Inspect the PVC events.

->
The StorageClass used by the PVC uses WaitForFirstConsumer volume binding mode. This means that the persistent volume will not bind to the claim until a pod makes use of the PVC to request storage.

root@controlplane:~# kubectl describe pvc local-pvc | grep -A3 Ev

controlplane ~ ✖ kubectl describe pvc local-pvc 
Name:          local-pvc
Namespace:     default
StorageClass:  local-storage
Status:        Pending
Volume:        
Labels:        <none>
Annotations:   <none>
Finalizers:    [kubernetes.io/pvc-protection]
Capacity:      
Access Modes:  
VolumeMode:    Filesystem
Used By:       <none>
Events:
  Type    Reason                Age                   From                         Message
  ----    ------                ----                  ----                         -------
  Normal  WaitForFirstConsumer  12s (x14 over 3m20s)  persistentvolume-controller  waiting for first consumer to be created before binding
---------------------------------------------------------------------------------------------------------------------

03. The Storage Class called local-storage makes use of VolumeBindingMode set to WaitForFirstConsumer. This will delay the binding and provisioning of a PersistentVolume until a Pod using the PersistentVolumeClaim is created.
Create a new pod called nginx with the image nginx:alpine. The Pod should make use of the PVC local-pvc and mount the volume at the path /var/www/html.
The PV local-pv should be in a bound state.

Pod created with the correct Image?
Pod uses PVC called local-pvc?
local-pv bound?
nginx pod running?
Volume mounted at the correct path?


---
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:alpine
    volumeMounts:
      - name: local-persistent-storage
        mountPath: /var/www/html
  volumes:
    - name: local-persistent-storage
      persistentVolumeClaim:
        claimName: local-pvc
		
controlplane ~ ➜  cat pod.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
    - name: nginx
      image: nginx:alpine
      volumeMounts:
      - mountPath: "/var/www/html"
        name: mypd
  volumes:
    - name: mypd
      persistentVolumeClaim:
        claimName: local-pvc
		
controlplane ~ ➜  kubectl get pvc
NAME        STATUS   VOLUME     CAPACITY   ACCESS MODES   STORAGECLASS    VOLUMEATTRIBUTESCLASS   AGE
local-pvc   Bound    local-pv   500Mi      RWO            local-storage   <unset>                 11m
--------------------------------------------------------------
Create a new Storage Class called delayed-volume-sc that makes use of the below specs:
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer

=>
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: delayed-volume-sc
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer

8.13 Why Stateful Sets? 09:28
8.14 Stateful Sets Introduction 02:44
8.15 Headless Services 07:29
8.16 Storage in StatefulSets 04:30
