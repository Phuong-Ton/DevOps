Modual 4: Multi-Container Pods - 6 Lessons
1. Multi-Container Pods 04:34
2. Practice Tests - Kubernetes CKAD - Multi Container Pods
3. Solution - Multi-Container Pods (Optional) 15:09
4. Init Containers
5. PRACTICE TEST – INIT CONTAINERS
6. Solution – Init Containers (Optional) 07:21

1. Multi-Container Pods 04:34
Design pattern:
Ambassador: depend on dev/ pro /test enviroment, change logic code to connect database.
Adapter: change format of log before sending to central server
Sidecar:send direct lof to central server

2. Practice Tests - Kubernetes CKAD - Multi Container Pods
2.1. Create a multi-container pod with 2 containers.
     Use the spec given below:  
     If the pod goes into the crashloopbackoff then add the command sleep 1000 in the lemon container.

controlplane ~ ➜  kubectl create -f lemon_pod.yaml 
pod/yellow created

controlplane ~ ➜  cat lemon_pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: yellow
  labels:
    name: yellow
    app: yellow-app
spec:
  containers:
    - name: gold
      image: redis

    - name: lemon
      image: busybox
      command:
        - sleep
        - "1000"
2.2 We have deployed an application logging stack in the elastic-stack namespace. Inspect it.

Before proceeding with the next set of questions, please wait for all the pods in the elastic-stack namespace to be ready. This can take a few minutes.

POD    Elastic-Search <----> Kibana ---> User
Once the pod is in a ready state, inspect the Kibana UI using the link above your terminal. There shouldn't be any logs for now.
We will configure a sidecar container for the application to send logs to Elastic Search.

NOTE: It can take a couple of minutes for the Kibana UI to be ready after the Kibana pod is ready.

You can inspect the Kibana logs by running:

kubectl -n elastic-stack logs kibana


controlplane ~ ➜  kubectl get pod,svc,nodes  -n elastic-stack
NAME                 READY   STATUS    RESTARTS   AGE
pod/app              1/1     Running   0          25m
pod/elastic-search   1/1     Running   0          25m
pod/kibana           1/1     Running   0          25m

NAME                    TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)                         AGE
service/elasticsearch   NodePort   10.111.33.9    <none>        9200:30200/TCP,9300:30300/TCP   25m
service/kibana          NodePort   10.98.44.180   <none>        5601:30601/TCP                  25m

NAME                STATUS   ROLES           AGE   VERSION
node/controlplane   Ready    control-plane   28m   v1.30.0



kubectl describe pod app -n elastic-stack

kubectl -n elastic-stack exec -it app -- cat /log/app.log
Edit the pod in the elastic-stack namespace to add a sidecar container to send logs to Elastic Search. Mount the log volume to the sidecar container.
Only add a new container. Do not modify anything else. Use the spec provided below.
Note: State persistence concepts are discussed in detail later in this course. For now please make use of the below documentation link for updating the concerning pod.



https://kubernetes.io/docs/tasks/access-application-cluster/communicate-containers-same-pod-shared-volume/

->
---
apiVersion: v1
kind: Pod
metadata:
  name: app
  namespace: elastic-stack
  labels:
    name: app
spec:
  containers:
  - name: app
    image: kodekloud/event-simulator
    volumeMounts:
    - mountPath: /log
      name: log-volume

  - name: sidecar
    image: kodekloud/filebeat-configured
    volumeMounts:
    - mountPath: /var/log/event-simulator/
      name: log-volume

  volumes:
  - name: log-volume
    hostPath:
      # directory location on host
      path: /var/log/webapp
      # this field is optional
      type: DirectoryOrCreate


controlplane ~ ➜  kubectl get pod app -n elastic-stack -o yaml> app.yaml
spec:
  containers:
  - image:  kodekloud/filebeat-configured
    name: sidecar
    volumeMounts:
      - mountPath: /var/log/event-simulator/
        name: log-volume

Inspect the Kibana UI. You should now see logs appearing in the Discover section.

You might have to wait for a couple of minutes for the logs to populate. You might have to create an index pattern to list the logs. If not sure check this video: https://bit.ly/2EXYdHf

3. Solution - Multi-Container Pods (Optional) 15:09
4. Init Containers
In a multi-container pod, each container is expected to run a process that stays alive as long as the POD’s lifecycle. For example in the multi-container pod that we talked about earlier that has a web application and logging agent, both the containers are expected to stay alive at all times. The process running in the log agent container is expected to stay alive as long as the web application is running. If any of them fail, the POD restarts.

But at times you may want to run a process that runs to completion in a container. For example, a process that pulls a code or binary from a repository that will be used by the main web application. That is a task that will be run only one time when the pod is first created. Or a process that waits for an external service or database to be up before the actual application starts. That’s where initContainers comes in.

An initContainer is configured in a pod-like all other containers, except that it is specified inside a initContainers section, like this:

apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
  labels:
    app: myapp
spec:
  containers:
  - name: myapp-container
    image: busybox:1.28
    command: \['sh', '-c', 'echo The app is running! && sleep 3600'\]
  initContainers:
  - name: init-myservice
    image: busybox
    command: \['sh', '-c', 'git clone &nbsp;;'\]
When a POD is first created the initContainer is run, and the process in the initContainer must run to a completion before the real container hosting the application starts.

You can configure multiple such initContainers as well, like how we did for multi-pod containers. In that case, each init container is run one at a time in sequential order.

If any of the initContainers fail to complete, Kubernetes restarts the Pod repeatedly until the Init Container succeeds.

apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
  labels:
    app: myapp
spec:
  containers:
  - name: myapp-container
    image: busybox:1.28
    command: \['sh', '-c', 'echo The app is running! && sleep 3600'\]
  initContainers:
  - name: init-myservice
    image: busybox:1.28
    command: \['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2; done;'\]
  - name: init-mydb
    image: busybox:1.28
    command: \['sh', '-c', 'until nslookup mydb; do echo waiting for mydb; sleep 2; done;'\]
Read more about initContainers here. And try out the upcoming practice test.

https://kubernetes.io/docs/concepts/workloads/pods/init-containers/

5. PRACTICE TEST – INIT CONTAINERS
Update the pod red to use an initContainer that uses the busybox image and sleeps for 20 seconds
Delete and re-create the pod if necessary. But make sure no other configurations change.    Command:

---
apiVersion: v1
kind: Pod
metadata:
  name: red
  namespace: default
spec:
  containers:
  - command:
    - sh
    - -c
    - echo The app is running! && sleep 3600
    image: busybox:1.28
    name: red-container
  initContainers:
  - image: busybox
    name: red-initcontainer
    command: 
      - "sleep"
      - "20"
6. Solution – Init Containers (Optional) 07:21
